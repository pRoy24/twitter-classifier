{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import operator\n",
    "from datetime import datetime\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "cluster = Cluster(['172.31.66.231'])\n",
    "session = cluster.connect('sharelock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def get_row_score(row):\n",
    "    user_score = 1\n",
    "    if (row['user_score'] > 1):\n",
    "        user_score = math.log(row['user_score'])\n",
    "    return (row['likes'] + row['retweets'] * 2 ) * user_score\n",
    "\n",
    "stop_ents = ['#', \"@\"]\n",
    "def is_valid_ent(ent):\n",
    "    stop_found = False\n",
    "    for stop in stop_ents:\n",
    "        if stop in ent:\n",
    "            stop_found = True\n",
    "    return ent != topic and not stop_found and len(ent) > 3\\\n",
    "               and not \"http\" in ent and not ent.replace(\" \", \"\").isdigit()\n",
    "\n",
    "def get_ent_dictionary(sorted_result, topic):\n",
    "    ent_dict = {}\n",
    "\n",
    "    for idx, row in sorted_result.iterrows():\n",
    "        text_item = row['tweet_text']\n",
    "        tweet_item = row\n",
    "        text_doc = nlp(row['tweet_text'])\n",
    "        for ent in text_doc.ents:\n",
    "            stripped_ent = ent.lemma_.strip()\n",
    "            if (is_valid_ent(stripped_ent)):\n",
    "                if stripped_ent in ent_dict.keys():\n",
    "                    for t in ent_dict[stripped_ent]:\n",
    "                        tFound = False\n",
    "                        if t['tweet_id'] == tweet_item['tweet_id']:\n",
    "                            tFound = True\n",
    "                            break   \n",
    "                        if not tFound:\n",
    "                            ent_dict[stripped_ent].append(tweet_item)\n",
    "                else:\n",
    "                    ent_dict[stripped_ent] = [tweet_item]               \n",
    "    return ent_dict            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_post_tag_map(row, ent_dict):\n",
    "    post_tag_dict = []\n",
    "    stop_ents = ['#', \"@\"]\n",
    "\n",
    "    text_item = row['tweet_text']\n",
    "    tweet_item = row\n",
    "    text_doc = nlp(row['tweet_text'])\n",
    "    tweet_id = row['tweet_id']\n",
    "    entity_list = []\n",
    "    for key in ent_dict:\n",
    "        frame_list = ent_dict[key]\n",
    "        for frame in frame_list:\n",
    "            if frame['tweet_id'] == tweet_id:\n",
    "                key_exists = [element for element in post_tag_dict if element['name'] == key]\n",
    "                if not key_exists:\n",
    "                    data = {}\n",
    "                    data[\"name\"] = key\n",
    "                    data[\"rank\"] = len(frame_list)\n",
    "                    post_tag_dict.append(data)\n",
    "    return post_tag_dict               \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2656\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "topic_list_query = \"SELECT * from sharelock.topic_list\"\n",
    "topic_rows = session.execute(topic_list_query)\n",
    "topic_row_list = list(topic_rows)\n",
    "topic_frames = pd.DataFrame(topic_row_list)  \n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "for idx, frame in topic_frames.iterrows():\n",
    "    topic = frame['topic']\n",
    "    category = frame['category']\n",
    "    query = \"SELECT * from sharelock.active_tweets where category='\"+category+\"'allow filtering\"\n",
    "    rows = session.execute(query)\n",
    "    row_list = list(rows)\n",
    "\n",
    "    result = []\n",
    "    ent_dict = {}    \n",
    "    if len(row_list) > 0:\n",
    "        print(len(row_list))\n",
    "        result = pd.DataFrame(row_list)   \n",
    "        result = result[result['topic'] == topic]\n",
    "\n",
    "        sorted_result = df = pd.DataFrame(data=result)\n",
    "\n",
    "        if not result.empty:\n",
    "            ent_dict = get_ent_dictionary(sorted_result, topic)\n",
    "            \n",
    "            for idx, row in result.iterrows():\n",
    "                post_ent_list = get_post_tag_map(row, ent_dict) \n",
    "                enity_score = 0\n",
    "                for ent in post_ent_list:\n",
    "                    enity_score = enity_score + ent['rank']\n",
    "\n",
    "                SQL_QUERY = \"INSERT INTO sharelock.tweet_tags_with_rank (tweet_id , topic, category, entity_list, entity_score) values (?,?,?,?, ?)\"\n",
    "                params = [row['tweet_id'], row['topic'], row['category'], json.dumps(post_ent_list), enity_score]\n",
    "                prepared = session.prepare(SQL_QUERY)\n",
    "                session.execute(prepared, params)\n",
    "                # Create api endpoint for posts with entity rankings  \n",
    "       \n",
    "        if ent_dict:\n",
    "            frame_score_list = {}\n",
    "\n",
    "            for key in ent_dict:\n",
    "                frame_score = 0\n",
    "                frame_list = ent_dict[key]\n",
    "                frame_tag = key\n",
    "                frame_tweet_list = []\n",
    "\n",
    "                for frame in frame_list:\n",
    "                    frame_score = frame_score + frame['raw_score']\n",
    "                    frame_obj = {}\n",
    "                    raw_score = frame['raw_score']\n",
    "                    tweet_id = frame['tweet_id']\n",
    "                    tweet_text = row['tweet_text']\n",
    "\n",
    "                    frame_tweet_list.append({\"id\": tweet_id, \"text\": tweet_text, \"score\": raw_score})\n",
    "                    \n",
    "                insert_time = int(datetime.utcnow().timestamp())   \n",
    "                insert_values = [topic, category, frame_tag, json.dumps(frame_tweet_list), frame_score, insert_time]\n",
    "                # print(insert_values)  \n",
    "                # [{id, text, score}, {}, {}, {}] {id, text, }\n",
    "                sql_query = \"INSERT INTO sharelock.filtered_tag_frame (topic, category, tag, tweet_map, frame_raw_score, inserted_at) values (?, ?, ?, ?, ?, ?)\"\n",
    "                prepared = session.prepare(sql_query)\n",
    "                session.execute(prepared, (insert_values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
